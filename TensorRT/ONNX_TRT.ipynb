{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11045e9c-1c05-417e-ad1a-47a1e7c3a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import logging\n",
    "\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model_id = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb11ecb-ef5f-47b1-8a63-a93d34a34f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.randint(0, len(tokenizer), (8, 128))\n",
    "attention_mask = torch.randint(0, 1, (8, 128))\n",
    "token_type_ids = torch.randint(0, 1, (8, 128))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _ = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cef495-e3ab-4a8e-b7e0-1e7b056089be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    (input_ids, attention_mask),\n",
    "    \"weights/model.onnx\",\n",
    "    input_names=['input_ids', 'attention_mask', 'token_type_ids'],\n",
    "    output_names=['last_hidden_state', 'pooler_output'],\n",
    "    dynamic_axes={\n",
    "        'input_ids': {0: 'batch_size'},\n",
    "        'attention_mask': {0: 'batch_size'},\n",
    "        'token_type_ids': {0: 'batch_size'},\n",
    "        'last_hidden_state': {0: 'batch_size'},\n",
    "        'pooler_output': {0: 'batch_size'},\n",
    "    },\n",
    "    opset_version=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bce27e6-2d04-4360-a529-bdff51767d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/22/2024-08:58:09] [TRT] [I] [MemUsageChange] Init CUDA: CPU +18, GPU +0, now: CPU 165, GPU 1021 (MiB)\n",
      "[08/22/2024-08:58:12] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2088, GPU +386, now: CPU 2408, GPU 1407 (MiB)\n",
      "[08/22/2024-08:58:13] [TRT] [I] ----------------------------------------------------------------\n",
      "[08/22/2024-08:58:13] [TRT] [I] Input filename:   weights/model.onnx\n",
      "[08/22/2024-08:58:13] [TRT] [I] ONNX IR version:  0.0.8\n",
      "[08/22/2024-08:58:13] [TRT] [I] Opset version:    17\n",
      "[08/22/2024-08:58:13] [TRT] [I] Producer name:    pytorch\n",
      "[08/22/2024-08:58:13] [TRT] [I] Producer version: 2.2.0\n",
      "[08/22/2024-08:58:13] [TRT] [I] Domain:           \n",
      "[08/22/2024-08:58:13] [TRT] [I] Model version:    0\n",
      "[08/22/2024-08:58:13] [TRT] [I] Doc string:       \n",
      "[08/22/2024-08:58:13] [TRT] [I] ----------------------------------------------------------------\n",
      "[08/22/2024-08:58:13] [TRT] [W] ModelImporter.cpp:420: Make sure input input_ids has Int64 binding.\n",
      "[08/22/2024-08:58:13] [TRT] [W] ModelImporter.cpp:420: Make sure input attention_mask has Int64 binding.\n",
      "Model parsed successfully.....\n"
     ]
    }
   ],
   "source": [
    "logger = trt.Logger(min_severity=trt.Logger.INFO)\n",
    "builder = trt.Builder(logger)\n",
    "\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "parser.parse_from_file(\"weights/model.onnx\")\n",
    "print(\"Model parsed successfully.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0727486e-be2a-4cfe-9a60-9f4fceec3ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = builder.create_builder_config()\n",
    "profile = builder.create_optimization_profile()\n",
    "\n",
    "min_shape = (1, 128)\n",
    "opt_shape = (1, 128)\n",
    "max_shape = (1, 128)\n",
    "\n",
    "profile.set_shape(\"input_ids\", min_shape,\n",
    "                  opt_shape, max_shape)\n",
    "profile.set_shape(\"attention_mask\", min_shape,\n",
    "                  opt_shape, max_shape)\n",
    "profile.set_shape(\"token_type_ids\", min_shape,\n",
    "                  opt_shape, max_shape)\n",
    "\n",
    "config.set_flag(trt.BuilderFlag.FP16)\n",
    "config.add_optimization_profile(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2273435-c627-4397-a7f4-27f05aea3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/22/2024-08:58:21] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[08/22/2024-08:58:48] [TRT] [I] Detected 2 inputs and 2 output network tensors.\n",
      "[08/22/2024-08:58:48] [TRT] [I] Total Host Persistent Memory: 32\n",
      "[08/22/2024-08:58:48] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[08/22/2024-08:58:48] [TRT] [I] Total Scratch Memory: 5177344\n",
      "[08/22/2024-08:58:48] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 1 steps to complete.\n",
      "[08/22/2024-08:58:48] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.017443ms to assign 1 blocks to 1 nodes requiring 5177344 bytes.\n",
      "[08/22/2024-08:58:48] [TRT] [I] Total Activation Memory: 5177344\n",
      "[08/22/2024-08:58:48] [TRT] [I] Total Weights Memory: 437930368\n",
      "[08/22/2024-08:58:48] [TRT] [I] Engine generation completed in 27.1043 seconds.\n",
      "[08/22/2024-08:58:48] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 208 MiB, GPU 423 MiB\n",
      "[08/22/2024-08:58:48] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 7002 MiB\n"
     ]
    }
   ],
   "source": [
    "engine = builder.build_serialized_network(network, config)\n",
    "with open(\"weights/model.trt\", \"wb\") as f:\n",
    "    f.write(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c485527-765e-41e0-8614-e3f5c68b19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46995f9-02da-41bd-9e90-e793fb81cfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['act', 'prompt'],\n",
       "        num_rows: 153\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataset\n",
    "prompt_dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "prompt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec11db6-46f6-480b-90b6-5e676ddcad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = trt.Logger(trt.Logger.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584e163c-5050-49c7-872a-a22ce64a0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7768e20-1f5d-442a-89fd-9057ef02c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/22/2024-10:55:32] [TRT] [I] Loaded engine size: 418 MiB\n",
      "[08/22/2024-10:55:32] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 422 (MiB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25002a94e3ce4fd0bc979904a52c9429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergae time (ms) : 5.426266614128561\n"
     ]
    }
   ],
   "source": [
    "with open(\"weights/model.trt\", \"rb\") as f, \\\n",
    "    trt.Runtime(logger) as runtime, \\\n",
    "    runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "    engine.create_execution_context() as context:\n",
    "\n",
    "    input_shape = (1, 128)\n",
    "    input_nbytes = trt.volume(input_shape) * trt.int32.itemsize * 5\n",
    "    \n",
    "    # Allocate device memory\n",
    "    d_input_ids = cuda.mem_alloc(input_nbytes)\n",
    "    d_attention_mask = cuda.mem_alloc(input_nbytes)\n",
    "\n",
    "    # Create the stream\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    # Set the shape\n",
    "    context.set_input_shape('input_ids', input_shape)\n",
    "    context.set_input_shape('attention_mask', input_shape)\n",
    "\n",
    "    h_pooler = cuda.pagelocked_empty(tuple(context.get_tensor_shape(engine.get_tensor_name(3))), dtype=np.float32)\n",
    "    d_pooler = cuda.mem_alloc(h_pooler.nbytes)\n",
    "    \n",
    "    h_hidden = cuda.pagelocked_empty(tuple(context.get_tensor_shape(engine.get_tensor_name(2))), dtype=np.float32)\n",
    "    d_hidden = cuda.mem_alloc(h_hidden.nbytes)\n",
    "\n",
    "    # Loop and check\n",
    "    # Get the total time\n",
    "    total = 0\n",
    "    for text in tqdm(prompt_dataset[\"train\"][\"prompt\"], total=len(prompt_dataset[\"train\"][\"prompt\"])):\n",
    "        # Start\n",
    "        start = time.time()\n",
    "        \n",
    "        # Tokenize the text\n",
    "        inputs = tokenizer(text, return_tensors=\"np\", padding=\"max_length\", max_length=128)\n",
    "        input_ids = np.array(inputs['input_ids'], dtype=np.int32, order=None)\n",
    "        attention_mask = np.array(inputs['input_ids'], dtype=np.int32, order=None)\n",
    "\n",
    "        # Push data to memory\n",
    "        input_ids = cuda.register_host_memory(np.ascontiguousarray(input_ids.ravel()))\n",
    "        attention_mask = cuda.register_host_memory(np.ascontiguousarray(attention_mask.ravel()))\n",
    "\n",
    "        # Copy to stream\n",
    "        cuda.memcpy_htod_async(d_input_ids, input_ids, stream)\n",
    "        cuda.memcpy_htod_async(d_attention_mask, attention_mask, stream)\n",
    "\n",
    "        # Set address for context manager\n",
    "        context.set_tensor_address(\"input_ids\", int(d_input_ids))\n",
    "        context.set_tensor_address(\"attention_mask\", int(d_attention_mask))\n",
    "        context.set_tensor_address(\"pooler_output\", int(d_pooler))\n",
    "        context.set_tensor_address(\"last_hidden_state\", int(d_hidden))\n",
    "\n",
    "        # Run the engine via the stream\n",
    "        context.execute_async_v3(stream_handle=stream.handle)\n",
    "        stream.synchronize()\n",
    "\n",
    "        # Fetch and sync outputs #########################\n",
    "        cuda.memcpy_dtoh_async(h_pooler, d_pooler, stream)\n",
    "        stream.synchronize()\n",
    "    \n",
    "        cuda.memcpy_dtoh_async(h_hidden, d_hidden, stream)\n",
    "        stream.synchronize()\n",
    "        ##################################################\n",
    "        \n",
    "        end = time.time()\n",
    "        total += (end - start) * 1000\n",
    "    \n",
    "print(f\"Avergae time (ms) : {total / len(prompt_dataset['train']['prompt'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9938fe-dab5-4470-8ac3-ce862f9ebd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "import logging\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c131a75-2c6c-40aa-9c74-a2a2a09452de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['act', 'prompt'],\n",
       "        num_rows: 153\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataset\n",
    "prompt_dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
    "prompt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2b977e-0939-43d3-9902-e5ee4b0f766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a9892e6a9540838cb496af0e440955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergae time (ms) : 9.301696727478426\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model\n",
    "model_id = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_id).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "for text in tqdm(prompt_dataset[\"train\"][\"prompt\"], total=len(prompt_dataset[\"train\"][\"prompt\"])):\n",
    "    # Start\n",
    "    start = time.time()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128)\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Get the inference\n",
    "    with torch.no_grad():\n",
    "        _ = model(**inputs)\n",
    "    \n",
    "    end = time.time()\n",
    "    total += (end - start) * 1000\n",
    "    \n",
    "print(f\"Avergae time (ms) : {total / len(prompt_dataset['train']['prompt'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
